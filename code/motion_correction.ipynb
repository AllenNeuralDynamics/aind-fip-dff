{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa918c8-1363-4eda-9572-401df64d3721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aind-data-schema              0.38.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f727d39-39ee-488a-b3e4-0b8e703baeee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (322 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.0/322.0 kB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.54.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m100.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.7-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (23.1)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.9/106.9 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.0 cycler-0.12.1 fonttools-4.54.1 kiwisolver-1.4.7 matplotlib-3.9.2 pillow-11.0.0 pyparsing-3.2.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m99.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.19.5 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.14.0)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Installing collected packages: joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4415fb3-5222-45e8-b4c5-bfc7f12b7033",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from multiprocessing.pool import Pool, ThreadPool\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from time import time\n",
    "\n",
    "import h5py\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hdmf_zarr import NWBZarrIO\n",
    "\n",
    "from aind_ophys_utils.signal_utils import median_filter\n",
    "from scipy.ndimage import uniform_filter1d\n",
    "from scipy.signal import butter, sosfilt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.api import RLM\n",
    "from statsmodels.robust.norms import HuberT, TukeyBiweight\n",
    "\n",
    "import utils.nwb_dict_utils as nwb_utils\n",
    "from utils.preprocess import batch_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94d00b64-d204-4b24-8b4b-f23c6080e315",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
    "pd.options.mode.copy_on_write = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ede5098-4b56-4d95-b5e4-de45d1050f0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def RMSE(x,y):\n",
    "    return np.sqrt(np.mean((x-y)**2, -1))\n",
    "\n",
    "def bias(x,y):\n",
    "    return np.mean(x-y, -1)\n",
    "\n",
    "def std_of_diff(x,y):\n",
    "    return np.std(x-y, -1)\n",
    "\n",
    "def corr(x, y):\n",
    "    x = x-x.mean(-1)[...,None]\n",
    "    x /= x.std(-1)[...,None]\n",
    "    y = y-y.mean(-1)[...,None]\n",
    "    y /= y.std(-1)[...,None]\n",
    "    return np.mean(x*y, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9e08ca6-1545-496f-ae0b-9ec24e2cb81e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/data/photometry/vary_a_max',\n",
       " '/data/photometry/vary_a_power',\n",
       " '/data/photometry/vary_attenuation',\n",
       " '/data/photometry/vary_b_bright',\n",
       " '/data/photometry/vary_b_fast',\n",
       " '/data/photometry/vary_b_inf',\n",
       " '/data/photometry/vary_b_slow',\n",
       " '/data/photometry/vary_corr_s',\n",
       " '/data/photometry/vary_decay',\n",
       " '/data/photometry/vary_motion_power',\n",
       " '/data/photometry/vary_noise_std',\n",
       " '/data/photometry/vary_t_bright',\n",
       " '/data/photometry/vary_t_fast',\n",
       " '/data/photometry/vary_t_slow']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parents = sorted(glob.glob(\"/data/photometry/vary*\"))\n",
    "parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0e408b2-f467-4bfa-8e2b-dccc5f87d6da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def evaluate(parent):\n",
    "#     perf = []\n",
    "#     params = []\n",
    "#     dFFs = []\n",
    "#     vary = parent.split('/')[-1][5:]\n",
    "#     for nwb_file in sorted(glob.glob(f\"{parent}/*/*.nwb\")):\n",
    "#         print(f\"Processing NWB file: {nwb_file}\")\n",
    "#         p = pd.read_csv(Path(nwb_file).parent / \"parameters.csv\", delimiter=\",\", index_col=0)\n",
    "#         p = list(p[vary])\n",
    "#         params.append([p[:3], p[3:6]])\n",
    "#         with h5py.File(Path(nwb_file).parent / 'groundtruth.h5') as file:\n",
    "#             dFF_gt = [file[f'fiber{f}']['dff'][:] for f in (0,1)]\n",
    "\n",
    "#         with NWBZarrIO(path=nwb_file, mode=\"r\") as io:\n",
    "#             nwb = io.read()\n",
    "#             # convert nwb to dataframe\n",
    "#             df_from_nwb = nwb_utils.nwb_to_dataframe(nwb)\n",
    "#             # add the session column\n",
    "#             filename = Path(nwb_file).name\n",
    "#             session_name = filename.split(\".\")[0].split(\"FIP_\")[1]\n",
    "#             df_from_nwb.insert(0, \"session\", session_name)\n",
    "#             # now pass the dataframe through the preprocessing function:\n",
    "#             df_fip_pp_nwb, df_PP_params = batch_processing(df_fip=df_from_nwb)\n",
    "#             # calculate performance measures\n",
    "#             tmp = []\n",
    "#             dFF = []\n",
    "#             for pre in (\"poly\", \"exp\", \"bright\"):\n",
    "#                 df = df_fip_pp_nwb[df_fip_pp_nwb[\"preprocess\"]==pre]\n",
    "#                 dFF.append(np.array([[df[(df[\"channel\"] == ch) & (df[\"fiber_number\"] == fiber)][\"signal\"]\n",
    "#                                  for ch in ['Iso', 'G', 'R']] for fiber in df_fip_pp_nwb[\"fiber_number\"].unique()]))\n",
    "#                 tmp.append([RMSE(dFF[-1], dFF_gt), bias(dFF[-1], dFF_gt), std_of_diff(dFF[-1], dFF_gt)])\n",
    "#             perf.append(tmp)\n",
    "#             dFFs.append(dFF)\n",
    "\n",
    "#     return (np.array(params), # indices: expId, fiber, channel\n",
    "#             np.array(perf),   # indices: expId, method, performance_measure, fiber, channel\n",
    "#             np.array(dFFs))   # indices: expId, method, fiber, channel, frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74bde2e-1f0d-4088-aa6b-16e4b7083d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b659cf8-7fb6-4c5e-b472-2b2c201f552a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.02 s, sys: 3.31 s, total: 6.33 s\n",
      "Wall time: 40min 47s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# %%capture\n",
    "# results = Pool(int(os.environ['CO_CPUS'])).map(evaluate, parents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f84472b-6377-4eae-93ef-af3b373cf889",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Save to a pickle file\n",
    "# with open('/scratch/comparison.pkl', 'wb') as f:\n",
    "#     pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9db9d0e8-bc46-4812-8eca-e4f63800f683",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load pickle file\n",
    "with open('/scratch/comparison.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f63a749-fa2e-4313-8d26-d420168c51b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3b32fd-cda3-4a4d-9343-ac5d6fae6e8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9f36b015-8adf-495f-9a8d-e3fa774ecbd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def motion_correct(dff, filt=lambda x: median_filter(x, 10), M=TukeyBiweight(1), filter_both=False, zero_mean=True):\n",
    "    motion = dff[0]\n",
    "    dff_filt = dff.copy()\n",
    "    if filt is not None:\n",
    "        motion = filt(motion)\n",
    "        if filter_both:\n",
    "            dff_filt = np.array(list(map(filt, dff)))\n",
    "    if M is not None:\n",
    "        motion = np.maximum([RLM(d, motion, M=M).fit().params for d in dff_filt], 0) * motion  # should we rather use robust regression?\n",
    "    else:\n",
    "        motion = LinearRegression(fit_intercept=False, positive=True\n",
    "                                 ).fit(motion[:,None], dff_filt.T).predict(motion[:,None]).T\n",
    "    dff_mc = dff - motion\n",
    "    if zero_mean:\n",
    "        dff_mc += motion.mean(-1)[...,None]\n",
    "    return dff_mc, motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1a444909-4968-4bc9-baf1-cdc1907e1768",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(row, filt=lambda x: x, M=TukeyBiweight(1), filter_both=False, zero_mean=True, pres=(\"bright\",)):\n",
    "    perf, perf_motion = [], []\n",
    "\n",
    "    parent = parents[row]\n",
    "    for exp_id, nwb_file in enumerate(sorted(glob.glob(f\"{parent}/*/*.nwb\"))):\n",
    "        # print(f\"Processing NWB file: {nwb_file}\")\n",
    "        with h5py.File(Path(nwb_file).parent / 'groundtruth.h5') as file:\n",
    "            dFF_gt = [file[f'fiber{f}/dff'][:] for f in (0,1)]\n",
    "            motion_gt = [file[f'fiber{f}/motion'][:] for f in (0,1)]\n",
    "        tmp = []\n",
    "        tmpm = []\n",
    "        for pre in pres:\n",
    "            dFFpre = results[row][2][exp_id, {\"poly\": 0, \"exp\": 1, \"bright\": 2}[pre]]\n",
    "            dFF, motion = np.transpose([motion_correct(dff, filt, M, filter_both, zero_mean) for dff in dFFpre], (1,0,2,3))\n",
    "            tmp.append([RMSE(dFF, dFF_gt), bias(dFF, dFF_gt), std_of_diff(dFF, dFF_gt)])\n",
    "            tmpm.append(np.array([[np.corrcoef(m,g)[0,1] for m,g in zip(motion[f], motion_gt[f])] for f in (0,1)]))\n",
    "        perf.append(tmp)\n",
    "        perf_motion.append(tmpm)\n",
    "    return perf, perf_motion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a7d1a1-8ed9-45ea-942e-e0acfef4719c",
   "metadata": {},
   "source": [
    "## look for a good M estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca30659b-87b4-4fe0-aba4-0ab86f8cf30d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "N = len(parents)\n",
    "Ms = [None, HuberT(), HuberT(1), HuberT(.5), HuberT(.25), HuberT(.1),\n",
    "      TukeyBiweight(), TukeyBiweight(2), TukeyBiweight(1), TukeyBiweight(.5), TukeyBiweight(.25)]\n",
    "keys = [\"OLS\", \"HuberT()\", \"HuberT(1)\", \"HuberT(.5)\", \"HuberT(.25)\", \"HuberT(.1)\",\n",
    "        \"TukeyBiweight()\", \"TukeyBiweight(2)\", \"TukeyBiweight(1.2)\", \"TukeyBiweight(1)\", \"TukeyBiweight(.8)\", \"TukeyBiweight(.5)\", \"TukeyBiweight(.25)\"]\n",
    "res = {}\n",
    "for k, m in zip(keys, Ms):\n",
    "    res[k] = ThreadPool(N).starmap(evaluate, zip(range(N), [lambda x: x]*N, [m]*N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "305a9ab1-f838-411b-9363-d711cafeb879",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method       RMSE        bias          std_of_diff\n",
      "OLS [ 0.00842387 -0.00449494  0.00664619]\n",
      "HuberT() [ 0.00821922 -0.00449494  0.00639203]\n",
      "HuberT(1) [ 0.00816905 -0.00449494  0.006327  ]\n",
      "HuberT(.5) [ 0.00810038 -0.00449494  0.00623643]\n",
      "HuberT(.25) [ 0.00807805 -0.00449494  0.00620658]\n",
      "HuberT(.1) [ 0.00807128 -0.00449494  0.00619747]\n",
      "TukeyBiweight() [ 0.00816661 -0.00449494  0.0063263 ]\n",
      "TukeyBiweight(2) [ 0.00791956 -0.00449494  0.00599633]\n",
      "TukeyBiweight(1.2) [ 0.00779914 -0.00449494  0.00582663]\n",
      "TukeyBiweight(1) [ 0.00776729 -0.00449494  0.00578071]\n",
      "TukeyBiweight(.8) [ 0.0077379  -0.00449494  0.00573725]\n",
      "TukeyBiweight(.5) [ 0.00781944 -0.00449494  0.00583018]\n",
      "TukeyBiweight(.25) [ 0.00838992 -0.00449494  0.00660273]\n"
     ]
    }
   ],
   "source": [
    "print(\"Method       RMSE        bias          std_of_diff\")\n",
    "for k in keys:\n",
    "    print(k, np.concatenate([np.squeeze(r[0]) for r in res[k]]).mean(0)[...,1:].mean((1,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40eb43e8-d7f4-4fa3-8996-11a671b15cd3",
   "metadata": {},
   "source": [
    "## look for a good filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "35d43f83-9440-4cef-b2ba-5cbe1c765493",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bw(sig, N, Wn):\n",
    "    sos = butter(N, Wn, fs=20, output='sos')\n",
    "    return sosfilt(sos, sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40c818c-2f14-4c31-9121-8a8339ae62ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "filters = [lambda x: median_filter(x, 10), lambda x: median_filter(x, 20), lambda x: median_filter(x, 50), lambda x: median_filter(x, 100),\n",
    "          lambda x: uniform_filter1d(x, 10), lambda x: uniform_filter1d(x, 20), lambda x: uniform_filter1d(x, 50), lambda x: uniform_filter1d(x, 100),\n",
    "           lambda x: bw(x, 2, .3), lambda x: bw(x, 2, 1), lambda x: bw(x, 2, 3),\n",
    "           lambda x: bw(x, 4, .3), lambda x: bw(x, 4, 1), lambda x: bw(x, 4, 3)]\n",
    "keys = [\"med10\", \"med20\", \"med50\", \"med100\", \"mean10\", \"mean20\", \"mean50\", \"mean100\",\n",
    "        \"bw2_.3\", \"bw2_1\", \"bw2_3\", \"bw4_.3\", \"bw4_1\", \"bw4_3\"]\n",
    "res2 = {}\n",
    "for k, f in zip(keys, filters):\n",
    "    res2[k] = ThreadPool(N).starmap(evaluate, zip(range(N), [f]*N, [TukeyBiweight(1)]*N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "972cca74-09cd-49c9-ae62-418164677f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method      RMSE       bias     std_of_diff\n",
      "med10 [ 0.00764844 -0.00449494  0.00560843]\n",
      "med20 [ 0.00763152 -0.00449494  0.00558691]\n",
      "med50 [ 0.00762363 -0.00449494  0.00557796]\n",
      "med100 [ 0.00761339 -0.00449494  0.0055639 ]\n",
      "mean10 [ 0.00766168 -0.00449494  0.0056293 ]\n",
      "mean20 [ 0.00763661 -0.00449494  0.00559566]\n",
      "mean50 [ 0.00761622 -0.00449494  0.00556811]\n",
      "mean100 [ 0.00760842 -0.00449494  0.00555757]\n",
      "bw2_.3 [ 0.00762732 -0.00449494  0.00558347]\n",
      "bw2_1 [ 0.00766725 -0.00449494  0.00563687]\n",
      "bw2_3 [ 0.00772482 -0.00449494  0.00571694]\n",
      "bw4_.3 [ 0.00762817 -0.00449494  0.00558525]\n",
      "bw4_1 [ 0.00766491 -0.00449494  0.00563372]\n",
      "bw4_3 [ 0.00772351 -0.00449494  0.00571514]\n"
     ]
    }
   ],
   "source": [
    "print(\"Method      RMSE       bias     std_of_diff\")\n",
    "for k in keys:\n",
    "    print(k, np.concatenate([np.squeeze(r[0]) for r in res2[k]]).mean(0)[...,1:].mean((1,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e235e0-4395-45c0-84ea-5de91f892c91",
   "metadata": {},
   "source": [
    "### filter both traces to estimate regression coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d941ce29-1745-489f-8a49-1fadb10e1286",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "filters = [lambda x: median_filter(x, 10), lambda x: median_filter(x, 20), lambda x: median_filter(x, 50), lambda x: median_filter(x, 100),\n",
    "          lambda x: uniform_filter1d(x, 10), lambda x: uniform_filter1d(x, 20), lambda x: uniform_filter1d(x, 25),\n",
    "           lambda x: uniform_filter1d(x, 30), lambda x: uniform_filter1d(x, 40), lambda x: uniform_filter1d(x, 50), lambda x: uniform_filter1d(x, 100),\n",
    "           lambda x: bw(x, 2, .1), lambda x: bw(x, 2, .3), lambda x: bw(x, 2, 1), lambda x: bw(x, 2, 3),\n",
    "           lambda x: bw(x, 4, .1), lambda x: bw(x, 4, .3), lambda x: bw(x, 4, 1), lambda x: bw(x, 4, 3),\n",
    "           lambda x: bw(x, 6, .1)]\n",
    "keys = [\"med10\", \"med20\", \"med50\", \"med100\", \"mean10\", \"mean20\", \"mean25\", \"mean30\", \"mean40\", \"mean50\", \"mean100\",\n",
    "        \"bw2_.1\", \"bw2_.3\", \"bw2_.5\", \"bw2_1\", \"bw2_3\", \"bw4_.1\", \"bw4_.3\", \"bw4_.5\", \"bw4_1\", \"bw4_3\", \"bw6_.1\", \"bw6_.3\", \"bw6_.5\"]\n",
    "res3 = {}\n",
    "for k, f in zip(keys, filters):\n",
    "    res3[k] = ThreadPool(N).starmap(evaluate, zip(range(N), [f]*N, [TukeyBiweight(1)]*N, [True]*N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b65a6571-0e51-4256-9b59-cdbf7c1feb2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "filters = [lambda x: uniform_filter1d(x, 25), lambda x: uniform_filter1d(x, 30), lambda x: uniform_filter1d(x, 40)]\n",
    "keys = [\"mean25\", \"mean30\", \"mean40\"]\n",
    "for k, f in zip(keys, filters):\n",
    "    res3[k] = ThreadPool(N).starmap(evaluate, zip(range(N), [f]*N, [TukeyBiweight(1)]*N, [True]*N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3cb53ee3-5f28-4d09-acfb-b5b14473ce06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "keys = [\"med10\", \"med20\", \"med50\", \"med100\", \"mean10\", \"mean20\", \"mean25\", \"mean30\", \"mean40\", \"mean50\", \"mean100\",\n",
    "        \"bw2_.1\", \"bw2_.3\", \"bw2_.5\", \"bw2_1\", \"bw2_3\", \"bw4_.1\", \"bw4_.3\", \"bw4_.5\", \"bw4_1\", \"bw4_3\", \"bw6_.1\", \"bw6_.3\", \"bw6_.5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "cee72fac-130b-4b19-b142-d29f49076827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method      RMSE       bias     std_of_diff\n",
      "med10 [ 0.00766165 -0.00449494  0.00562709]\n",
      "med20 [ 0.00761504 -0.00449494  0.00556521]\n",
      "med50 [ 0.00759686 -0.00449494  0.00554365]\n",
      "med100 [ 0.00762321 -0.00449494  0.00558331]\n",
      "mean10 [ 0.00760264 -0.00449494  0.00554888]\n",
      "mean20 [ 0.00758509 -0.00449494  0.00552581]\n",
      "mean25 [ 0.00758481 -0.00449494  0.00552589]\n",
      "mean30 [ 0.00758622 -0.00449494  0.00552833]\n",
      "mean40 [ 0.00759213 -0.00449494  0.00553733]\n",
      "mean50 [ 0.00759894 -0.00449494  0.00554777]\n",
      "mean100 [ 0.00764128 -0.00449494  0.00561139]\n",
      "bw2_.1 [ 0.00763436 -0.00449494  0.00559698]\n",
      "bw2_.3 [ 0.00758191 -0.00449494  0.0055218 ]\n",
      "bw2_.5 [ 0.00763436 -0.00449494  0.00559698]\n",
      "bw2_1 [ 0.00760632 -0.00449494  0.00555363]\n",
      "bw2_3 [ 0.00767973 -0.00449494  0.00565617]\n",
      "bw4_.1 [ 0.00763794 -0.00449494  0.00560137]\n",
      "bw4_.3 [ 0.00758095 -0.00449494  0.00552025]\n",
      "bw4_.5 [ 0.00763794 -0.00449494  0.00560137]\n",
      "bw4_1 [ 0.00760273 -0.00449494  0.00554882]\n",
      "bw4_3 [ 0.00767714 -0.00449494  0.00565255]\n",
      "bw6_.1 [ 0.00764614 -0.00449494  0.00561227]\n",
      "bw6_.3 [ 0.00764614 -0.00449494  0.00561227]\n",
      "bw6_.5 [ 0.00763436 -0.00449494  0.00559698]\n"
     ]
    }
   ],
   "source": [
    "print(\"Method      RMSE       bias     std_of_diff\")\n",
    "for k in keys:\n",
    "    print(k, np.concatenate([np.squeeze(r[0]) for r in res3[k]]).mean(0)[...,1:].mean((1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf86eee-6ed2-4417-9b93-4ffb615c4f79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2013d98-35b7-4160-b2cf-ff79d4cc22c6",
   "metadata": {},
   "source": [
    "### moving average works well, try some more windowing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3923cf03-667c-4798-80ca-b9aa3060b16d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def smooth_signal(source, window_len=10, window='flat'):\n",
    "    \"\"\"Smooth the data using a window with requested size.\n",
    "    \n",
    "    This method is based on the convolution of a scaled window with the signal.\n",
    "    The signal is prepared by introducing reflected copies of the signal \n",
    "    (with the window size) in both ends so that transient parts are minimized\n",
    "    in the begining and end part of the output signal.\n",
    "    \n",
    "    Args :  source (arr) = the input signal \n",
    "            window_len (int) = the dimension of the smoothing window; should be an odd integer\n",
    "            window (str) = the type of window from 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\n",
    "            flat window will produce a moving average smoothing.\n",
    "\n",
    "    Returns : sink = the smoothed signal\n",
    "    \n",
    "    Code taken from (https://scipy-cookbook.readthedocs.io/items/SignalSmooth.html)\n",
    "    \"\"\"\n",
    "\n",
    "    if source.ndim != 1:\n",
    "        raise ValueError(\"smooth only accepts 1 dimension arrays.\")\n",
    "\n",
    "    if source.size < window_len:\n",
    "        raise ValueError(\"Input vector needs to be bigger than window size.\")\n",
    "\n",
    "\n",
    "    if window_len < 3:\n",
    "        return source\n",
    "\n",
    "    if window not in ('flat', 'hanning', 'hamming', 'bartlett', 'blackman'):\n",
    "        raise ValueError(\"Window is on of 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\")\n",
    "\n",
    "    # s = np.r_[source[window_len-1:0:-1], source, source[-2:-window_len-1:-1]]\n",
    "    s = np.r_[source[(window_len)//2:0:-1], source, source[-2:-window_len//2-1:-1]]\n",
    "\n",
    "    if window == 'flat':  # moving average\n",
    "        w = np.ones(window_len, 'd')\n",
    "    else:\n",
    "        w = eval('np.'+window+'(window_len)')\n",
    "\n",
    "    sink = np.convolve(w/w.sum(), s, mode='valid')\n",
    "    return sink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c5094a11-65fa-42e5-a956-5abc6110db38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "filters = [lambda x: smooth_signal(x, 20, 'hanning'), lambda x: smooth_signal(x, 50, 'hanning'),\n",
    "          lambda x: smooth_signal(x, 20, 'hamming'), lambda x: smooth_signal(x, 50, 'hamming'), \n",
    "          lambda x: smooth_signal(x, 20, 'bartlett'), lambda x: smooth_signal(x, 50, 'bartlett'), \n",
    "          lambda x: smooth_signal(x, 20, 'blackman'), lambda x: smooth_signal(x, 50, 'blackman'), ]\n",
    "keys = [\"han20\", \"han50\", \"ham20\", \"ham50\", \"bar20\", \"bar50\", \"bla20\", \"bla50\"]\n",
    "res4 = {}\n",
    "for k, f in zip(keys, filters):\n",
    "    res4[k] = ThreadPool(N).starmap(evaluate, zip(range(N), [f]*N, [TukeyBiweight(1)]*N, [True]*N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "348de216-72b9-48a3-9e78-c38d4589d059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method      RMSE       bias     std_of_diff\n",
      "han20 [ 0.00759225 -0.00449494  0.00553483]\n",
      "han50 [ 0.00758507 -0.00449494  0.00552676]\n",
      "ham20 [ 0.00758878 -0.00449494  0.00553023]\n",
      "ham50 [ 0.00758729 -0.00449494  0.00553004]\n",
      "bar20 [ 0.00758858 -0.00449494  0.00552994]\n",
      "bar50 [ 0.0075875  -0.00449494  0.00553036]\n",
      "bla20 [ 0.00759813 -0.00449494  0.00554277]\n",
      "bla50 [ 0.00758381 -0.00449494  0.0055247 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"Method      RMSE       bias     std_of_diff\")\n",
    "for k in keys:\n",
    "    print(k, np.concatenate([np.squeeze(r[0]) for r in res4[k]]).mean(0)[...,1:].mean((1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d97403-7227-4b92-ac38-926f16dc2c85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a01a0158-2789-40de-807c-512e10c94c7b",
   "metadata": {},
   "source": [
    "## check that the M estimator we found without any filtering still performs best with filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d30c68c2-e205-45af-80ec-b39ed22b982f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "N = len(parents)\n",
    "Ms = [None, HuberT(.5), HuberT(.25), HuberT(.1),\n",
    "      TukeyBiweight(2), TukeyBiweight(1.2), TukeyBiweight(1), TukeyBiweight(.8), TukeyBiweight(.5)]\n",
    "keys = [\"OLS\", \"HuberT(.5)\", \"HuberT(.25)\", \"HuberT(.1)\",\n",
    "        \"TukeyBiweight(2)\", \"TukeyBiweight(1.2)\", \"TukeyBiweight(1)\", \"TukeyBiweight(.8)\", \"TukeyBiweight(.5)\"]\n",
    "res5 = {}\n",
    "for k, m in zip(keys, Ms):\n",
    "    res5[k] = ThreadPool(N).starmap(evaluate, zip(range(N), [lambda x: bw(x, 2, .3)]*N, [m]*N, [True]*N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c1f07d95-b038-4f01-bd34-e3994ebbbffa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method       RMSE        bias          std_of_diff\n",
      "OLS [ 0.00839741 -0.00449494  0.00661027]\n",
      "HuberT(.5) [ 0.007968   -0.00449494  0.00606435]\n",
      "HuberT(.25) [ 0.00794446 -0.00449494  0.00603281]\n",
      "HuberT(.1) [ 0.00793756 -0.00449494  0.00602352]\n",
      "TukeyBiweight(2) [ 0.00772541 -0.00449494  0.00573469]\n",
      "TukeyBiweight(1.2) [ 0.00760775 -0.00449494  0.00556167]\n",
      "TukeyBiweight(1) [ 0.00758191 -0.00449494  0.0055218 ]\n",
      "TukeyBiweight(.8) [ 0.0075672  -0.00449494  0.00549671]\n",
      "TukeyBiweight(.5) [ 0.00777972 -0.00449494  0.00577042]\n"
     ]
    }
   ],
   "source": [
    "print(\"Method       RMSE        bias          std_of_diff\")\n",
    "for k in keys:\n",
    "    print(k, np.concatenate([np.squeeze(r[0]) for r in res5[k]]).mean(0)[...,1:].mean((1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ba5a5436-a73f-4b91-805a-17f7123e10f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "N = len(parents)\n",
    "Ms = [TukeyBiweight(1.2), TukeyBiweight(1), TukeyBiweight(.8), TukeyBiweight(.5)]\n",
    "keys = [\"TukeyBiweight(1.2)\", \"TukeyBiweight(1)\", \"TukeyBiweight(.8)\", \"TukeyBiweight(.5)\"]\n",
    "res6 = {}\n",
    "for k, m in zip(keys, Ms):\n",
    "    res6[k] = ThreadPool(N).starmap(evaluate, zip(range(N), [lambda x: uniform_filter1d(x, 20)]*N, [m]*N, [True]*N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "71b50cdb-13ad-40ac-b7c6-81587d2fbbf8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method       RMSE        bias          std_of_diff\n",
      "TukeyBiweight(1.2) [ 0.00761396 -0.00449494  0.00556976]\n",
      "TukeyBiweight(1) [ 0.00758509 -0.00449494  0.00552581]\n",
      "TukeyBiweight(.8) [ 0.0075654  -0.00449494  0.00549455]\n",
      "TukeyBiweight(.5) [ 0.00777234 -0.00449494  0.00575991]\n"
     ]
    }
   ],
   "source": [
    "print(\"Method       RMSE        bias          std_of_diff\")\n",
    "for k in keys:\n",
    "    print(k, np.concatenate([np.squeeze(r[0]) for r in res6[k]]).mean(0)[...,1:].mean((1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53c869f-7e21-4a7b-b5f5-4285513c7204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b8a6d5-063c-4d84-a587-a63f8d2f0734",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054d2328-d13a-4f57-a338-fc16767c43a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f503a8a0-ff3d-4e65-92cb-fc95c0d417a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(self, maxiter=50, tol=1e-8, scale_est='mad', init=None, cov='H1',\n",
    "            update_scale=True, conv='dev', start_params=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "770aa506-1a9c-43aa-89bb-5ba9c0996263",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def motion_correct0(dff, filt=lambda x: median_filter(x, 10), M=TukeyBiweight(1), zero_mean=True):\n",
    "    motion = dff[0]\n",
    "    if filt is not None:\n",
    "        motion = filt(motion)\n",
    "    if M is not None:\n",
    "        motion = np.maximum([RLM(d, motion, M=M).fit(tol=1e-5).params for d in dff], 0) * motion  # should we rather use robust regression?\n",
    "    else:\n",
    "        # motion = LinearRegression().fit(motion[:,None], dff.T).coef_ * motion\n",
    "        motion = LinearRegression(fit_intercept=False, positive=True\n",
    "                                 ).fit(motion[:,None], dff.T).predict(motion[:,None]).T\n",
    "    dff_mc = dff - motion\n",
    "    if zero_mean:\n",
    "        dff_mc += motion.mean(-1)[...,None]\n",
    "    return dff_mc, motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5da461d1-c56f-46be-acd8-528d9832bacf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate0(row, filt=lambda x: x, M=TukeyBiweight(1), zero_mean=True, pres=(\"bright\",)):\n",
    "    perf, perf_motion = [], []\n",
    "\n",
    "    parent = parents[row]\n",
    "    for exp_id, nwb_file in enumerate(sorted(glob.glob(f\"{parent}/*/*.nwb\"))):\n",
    "        # print(f\"Processing NWB file: {nwb_file}\")\n",
    "        with h5py.File(Path(nwb_file).parent / 'groundtruth.h5') as file:\n",
    "            dFF_gt = [file[f'fiber{f}/dff'][:] for f in (0,1)]\n",
    "            motion_gt = [file[f'fiber{f}/motion'][:] for f in (0,1)]\n",
    "        tmp = []\n",
    "        tmpm = []\n",
    "        for pre in pres:\n",
    "            dFFpre = results[row][2][exp_id, {\"poly\": 0, \"exp\": 1, \"bright\": 2}[pre]]\n",
    "            dFF, motion = np.transpose([motion_correct0(dff, filt, M, zero_mean) for dff in dFFpre], (1,0,2,3))\n",
    "            tmp.append([RMSE(dFF, dFF_gt), bias(dFF, dFF_gt), std_of_diff(dFF, dFF_gt)])\n",
    "            tmpm.append(np.array([[np.corrcoef(m,g)[0,1] for m,g in zip(motion[f], motion_gt[f])] for f in (0,1)]))\n",
    "        perf.append(tmp)\n",
    "        perf_motion.append(tmpm)\n",
    "    return perf, perf_motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "20fad98a-6a4c-495c-808e-5f6002fbfb54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "tic = -time()\n",
    "res0 = ThreadPool(N).map(evaluate0, range(N))\n",
    "tic += time()\n",
    "print(tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c3bdbab3-0d74-4cca-b303-63aca6526cd9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(274.697473526001, array([ 0.00776729, -0.00449494,  0.00578071]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit(tol=1e-5)\n",
    "tic, np.concatenate([np.squeeze(r[0]) for r in res0]).mean(0)[...,1:].mean((1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8dcbd8d4-23db-4b2a-a897-603a739e1347",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173.51955890655518, array([ 0.0077686 , -0.00449494,  0.00578242]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit(maxiter=30)\n",
    "tic, np.concatenate([np.squeeze(r[0]) for r in res0]).mean(0)[...,1:].mean((1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b104417e-0da3-45f8-aa81-60e2022f3fc9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275.6970102787018, array([ 0.00776729, -0.00449494,  0.00578071]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit() w/o params\n",
    "tic, np.concatenate([np.squeeze(r[0]) for r in res0]).mean(0)[...,1:].mean((1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaf7cb5-f570-4e6f-9a35-475cdf673ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
